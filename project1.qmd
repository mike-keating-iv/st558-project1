---
title: "Project 1"
author: "Mike Keating, Hayden Morgan"
format: pdf
editor: visual
---

# Project 1

## First Steps

```{r, message=FALSE}
# Dependencies
#| warnings: false
#| messages: false
suppressWarnings(library("tidyverse"))
suppressWarnings(library("ggplot2"))
```

Here we can first attempt each task/Step and then refactor into functions later.

## Step 1: Select Data

Read in one section of the data. This data is available at <https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv>.

Select only the following columns:

-   Area_name (rename area_name)

-   STCOU

-   Any column that ends in "D"

```{r}
#NOTE: The file has been downloaded and is in our data folder 
# TODO: Read data
# TODO: Hayden

edu01a <- read_csv("data/EDU01a.csv", col_select = c(Area_name, STCOU, ends_with("D")), show_col_types = FALSE) |>
  rename(
    area_name = Area_name
  )

```

Display the first 5 rows of your new data set to show that you created this correctly. Note: Do not save over your new data set with just the first 5 rows, simply just show the first 5 rows.

```{r}

head(edu01a, 5)

```

## Step 2: Long Format

Convert the data into long format where each row has only one enrollment value for that Area_name. Display the first 5 rows of your new data set to show that you created this correctly.

```{r}
# TODO: Convert to long format
# Hayden

edu01a_long <- edu01a |>
                  pivot_longer(cols = 3:12,
                               names_to = "EDU_D",
                               values_to = "Enrollment")

head(edu01a_long, 5)
```

## Step 3: Assign Year and State

One of the new columns should now correspond to the old column names that end with a “D”. All columns in these census data files will have this similar format. The first three characters represent the survey with the next four representing the type of value you have from that survey. The last two digits prior to the “D” represent the year of the measurement. For more about the variables see the data information sheet Mastdata.xls).

-   Parse the string to pull out the year and convert the year into a numeric value such as 1997 or 2002.

-   Grab the first three characters and following four digits to create a new variable representing which measurement was grabbed.

-   Hint: Check out the substr() function from base r

    ```{r}
    # TODO: Mike

    # Parse the string to pull out year
    # It looks like every year is pre-2000, but lets plan for up to 2025
    # This assumes there is no data from 1925 or earlier
    # Treating year as numeric for now
    long_updated <- edu01a_long |> mutate(year = as.numeric(substr(EDU_D, 8,9)), measurement = substr(EDU_D, 1,7)) |> 
      mutate(year = ifelse(year < 26, year + 2000, year + 1900))

    head(long_updated)

    ```

## Step 4: Split County and Non-County

Create two data sets

-   one data set that contains only non-county data

-   one data set that contains only county level data

Note that all county measurements have the format “County Name, DD” where “DD” represents the state. This can be used to subset the data. I used the code grep(pattern = ", \\w\\w", Area_name) to get the indices corresponding to counties. For the county level data, add a class to the tibble called county. Similarly, add a class to the non-county data called state. This can be done by overwriting the class() you see on the object: class(your_county_tibble) \<- c("county", class(your_county_tibble))

For the county level data, add a class to the tibble called county. Similarly, add a class to the non-county data called state. This can be done by overwriting the class() you see on the object:

```{r}
#For county tibble
county_match <- grep(pattern = ", \\w\\w", long_updated$area_name)
county_tibble <- long_updated[county_match,]
class(county_tibble) <- c("county", class(county_tibble))

#For state tibble
state_match <- grep(pattern = ", \\w\\w", long_updated$area_name, invert = T)
state_tibble <- long_updated[state_match,]
class(state_tibble) <- c("state", class(state_tibble))

```

Print the first 10 rows of each tibble by including county_tibble and state_tibble in your code chunk.

```{r}
# TODO Hayden

head(county_tibble, 10)
head(state_tibble, 10)

```

## Step 5: Assign State to County Tibble

For the county level tibble, create a new variable that describes which state one of these county measurements corresponds to (the two digit abbreviation is fine, see substr()).

```{r}

# I prefer to split the string based on delimiter (comma) instead of indexing
# Example
string <- "Autauga, AL"
split <- str_split(string, ",", simplify = TRUE)[,-1] # We return a chr matrix, and we only care about the last (second) entry

print(split)
print("Removing space")
clean_split <- str_trim(split)
print(clean_split)

```

```{r}
# TODO: Create state variable
# Mike

county_tibble <- county_tibble |> 
  mutate(state = str_trim(str_split(area_name, ",", simplify = TRUE)[,-1]))
```

## Step 6: Assign Division to State Tibble

For the non-county level tibble, create a new variable called “division” corresponding to the state’s classification of division [here.](https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States) If row corresponds to a non-state (i.e. UNITED STATES), return ERROR for the division. Hint: Use %in% and consider if_else or case_when logic.

Instead of writing ifelse statements manually for every division, we are going to instead read the divisions straight from Wikipedia and assign the correct division to any given state.

We can scrape a Wikipedia table using the rvest package.

Source: [StackOverflow](https://stackoverflow.com/questions/73696551/r-webscraping-error-arguments-imply-differing-number-of-rows)

```{r, message=FALSE}
# To do: Mike
library(rvest) # rvest is in the tidyverse package
# 

# Since we don't want to always have to connect to the url to read our data, 
# let's check if we have already saved it
if (file.exists("data/divisions.csv")){
  print("Division data already downloaded from Wikipedia")
  print("Reading .csv file")
  divisions <- read_csv("data/divisions.csv")
} else {
  print("No division data found. Downloading from Wikipedia...")
  wiki <- read_html(x = "https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States", package="xml2")
  wiki |> html_elements(".wikitable") |> html_table() -> wiki_tables
  # There is only one table, so the first one will give us what we want
  divisions <- wiki_tables[1]
  # Write the file to csv
  write.csv(divisions, file= "data/divisions.csv")
  print("data/divisions.csv successfully created!")
}

divisions

```

Note how all states in any given region are stored in the same cell, separated by spaces. We can either transform the States column by splitting up the states or leave as is and process the state correctly when reading our other datasets.

We can filter columns by the state in our divisions tibble by using if_any and str_detect.

```{r}
# TODO: Assign division based on the state-division pairs we read in
# Let's make a function to make this easier

divisions$States <-divisions$States |> toupper() # make sure uppercase to make matching easier

get_division_for_state <- function(state_name){
  
  # Check for the state name in the divisions df and filter
  # Assumes state only appears once in the tibble
  # Add word boundaries to our regex to avoid substring matching
  # E.g "Kansas" shouldnt match "Arkansas"
  match_pattern <- paste0("\\b", toupper(state_name), "\\b")
  division_row <- divisions |> 
    filter(if_any(States, ~str_detect(.x, match_pattern)))
  division <- division_row$Division
  # Return "ERROR" if there is no match to state
  if (length(division) == 0){
    return ("ERROR")
  }
  else {
    return (division)
  }
  
}

```

```{r}
# Apply our function to the non county tibble

state_tibble_test <- state_tibble |> mutate(division = map_chr(area_name, get_division_for_state))
tail(state_tibble)
```

## Function Wrapping

### Function 1: Step 1, Step 2

Write one function that combines Steps 1 and 2 above. Give an optional argument (that is it has a default value) that allows the user to specify the name of the column representing the value (enrollment for these data sets).

```{r}

select_and_convert <- function(data_path_in_quotes, value_colname = "Enrollment"){
  edu <- read_csv(data_path_in_quotes, col_select = c(Area_name, STCOU, ends_with("D")), show_col_types = FALSE) |>
  rename(
    area_name = Area_name
  )
  
  edu_long <- edu |>
                pivot_longer(cols = 3:12,
                             names_to = "EDU_D",
                             values_to = value_colname)
  print(head(edu_long, 5))
  return(edu_long)
}

```

### Function 2: Step 3

Write a function that takes the output from Step 2 and performs Step 3

```{r}

get_year_and_measurement <-function(long_data){
  print("Updating long data with year and measurement")
  long_data_updated <- long_data |> 
    mutate(year = as.numeric(substr(EDU_D, 8,9)), 
           measurement = substr(EDU_D, 1,7)) |> 
    mutate(year = ifelse(year < 26, year + 2000, year + 1900))
     
  return (long_data_updated)

}

```

### Function 3: Step 5

Write a function to do Step 5

```{r}
get_state <- function(county_tibble){
  print("Assigning State to county tibble")
  county_tibble_with_state <- county_tibble |> 
  mutate(state = str_trim(str_split(area_name, ",", simplify = TRUE)[,-1]))
  
  return(county_tibble_with_state)
}
```

### Function 4: Step 6

Write a function to do step 6

```{r}
get_division <- function(state_tibble){
  print("Assigning division to state tibble")
  state_tibble_with_division <- state_tibble |> 
    mutate(division = map_chr(area_name, get_division_for_state))
  
  return(state_tibble_with_division)

}

state_tibble
```

### Function 5: Step 4

Write another function that takes in the output from Step 3 and creates the two tibbles in Step 4, calls the above two functions (to perform Steps 5 and 6), and returns two final tibbles.

```{r}
#TODO: Hayden

returning_final_tibbles <- function(long_updated_data){
  county_match <- grep(pattern = ", \\w\\w", long_updated_data$area_name)
  county_tibble <- long_updated_data[county_match,]
  class(county_tibble) <- c("county", class(county_tibble))
  
  state_match <- grep(pattern = ", \\w\\w", long_updated_data$area_name, invert = T)
  state_tibble <- long_updated_data[state_match,]
  class(state_tibble) <- c("state", class(state_tibble))
  
  county_tibble_final <- get_state(county_tibble)
  state_tibble_final <- get_division(state_tibble)
  
  return(list(county_tibble_final, state_tibble_final))
}

```

## Wrap Everything in One Function Call

```{r}
# In progress
clean_data_wrapper <- function(url, value = "Enrollment"){
  result <- select_and_convert(url, value_colname = value) |>
    get_year_and_measurement() |> 
    returning_final_tibbles() 
    
}
```

## Call It and Combine Data

```{r}
data <- clean_data_wrapper("https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv")
data
```

## Write Generic Function for Summarizing

Let's show commas in our y-axis to make it more readable.

Source: [StackOverflow](https://stackoverflow.com/questions/52602503/display-an-axis-value-in-millions-in-ggplot)

```{r}
plot.state <- function(df, var_name = "Enrollment"){
  plot_title <- paste0("Mean ", var_name, " by Division")
  
  
  df |> 
    filter(division != "ERROR") |>
    group_by(division, year) |> 
    summarize(mean_enrollment = mean(get(var_name))) |>
    mutate(division = as.factor(division)) |>
    ggplot(aes(year,mean_enrollment, color = division)) +
    geom_line() + labs(title = plot_title, x = "Year", y = paste0("Mean ", var_name)) +
    guides(color = guide_legend("U.S. Division")) +
    scale_y_continuous(label=comma)
    
}
```

```{r}
plot(state_tibble_test)
```

## Put It Together
